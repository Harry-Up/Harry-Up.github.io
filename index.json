[{"authors":["admin"],"categories":null,"content":"I am currently a Ph.D. candidate in Computer Science and Technology at Data Mining Lab, School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC). I received my Bachelor‘s in Electronic Information Engineering from UESTC and Electronic Information Engineering from University of Glasgow (UoG) in 2017.\nMy research interests include interpretable machine learning, transfer Learning, continual / lifelong learning, few-shot learning, meta-learning and adversarial learning. Please feel free to discuss with me.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1562229336,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"http://weihan95.com/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am currently a Ph.D. candidate in Computer Science and Technology at Data Mining Lab, School of Computer Science and Engineering, University of Electronic Science and Technology of China (UESTC). I received my Bachelor‘s in Electronic Information Engineering from UESTC and Electronic Information Engineering from University of Glasgow (UoG) in 2017.\nMy research interests include interpretable machine learning, transfer Learning, continual / lifelong learning, few-shot learning, meta-learning and adversarial learning. Please feel free to discuss with me.","tags":null,"title":"Wei Han","type":"authors"},{"authors":[],"categories":null,"content":"","date":1701180000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701180000,"objectID":"93778c40f4f6c25b4e6fafcd4b76818d","permalink":"http://weihan95.com/talk/roadmap-to-llm-based-researches/","publishdate":"2021-09-28T20:00:00Z","relpermalink":"/talk/roadmap-to-llm-based-researches/","section":"talk","summary":" ","tags":[],"title":"Roadmap to LLM-based Researches","type":"talk"},{"authors":["Wei Han","Zhili Qin","Jiaming Liu","Christian Boehm","Junming Shao"],"categories":null,"content":"","date":1693353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1693353600,"objectID":"36f355bc975647078713d656f01f89f3","permalink":"http://weihan95.com/publication/tnnls2023/","publishdate":"2023-08-30T00:00:00Z","relpermalink":"/publication/tnnls2023/","section":"publication","summary":"Synchronization is a ubiquitous phenomenon in nature that enables the orderly presentation of information. In the human brain, for instance, functional modules such as the visual, motor, and language cortices form through neuronal synchronization. Inspired by biological brains and previous neuroscience studies, we propose an interpretable neural network incorporating a synchronization mechanism. The basic idea is to constrain each neuron, such as a convolution filter, to capture a single semantic pattern while synchronizing similar neurons to facilitate the formation of interpretable functional modules. Specifically, we regularize the activation map of a neuron to surround its focus position of the activated pattern in a sample. Moreover, neurons locally interact with each other, and similar ones are synchronized together during the training phase adaptively. Such local aggregation preserves the globally distributed representation nature of the neural network model, enabling a reasonably interpretable representation. To analyze the neuron interpretability comprehensively, we introduce a series of novel evaluation metrics from multiple aspects. Qualitative and quantitative experiments demonstrate that the proposed method outperforms many state-of-the-art algorithms in terms of interpretability. The resulting synchronized functional modules show module consistency across data and semantic specificity within modules.","tags":["Interpretable Neural Networks","Synchronization","Active Interpretability","Interpretability Metrics"],"title":"Synchronization-inspired Interpretable Neural Networks","type":"publication"},{"authors":[],"categories":null,"content":"","date":1686664800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686664800,"objectID":"48c00c38c166399502f9a6af6bf9f586","permalink":"http://weihan95.com/talk/locating-and-editing-knowledge-in-gpt/","publishdate":"2023-06-13T20:00:00Z","relpermalink":"/talk/locating-and-editing-knowledge-in-gpt/","section":"talk","summary":" ","tags":[],"title":"Locating and Editing Knowledge in GPT","type":"talk"},{"authors":[],"categories":null,"content":"","date":1669125600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669125600,"objectID":"4fd785ea29fcea53955554e67c643b59","permalink":"http://weihan95.com/talk/can-interpretability-help/","publishdate":"2022-11-22T20:00:00Z","relpermalink":"/talk/can-interpretability-help/","section":"talk","summary":" ","tags":[],"title":"Can Interpretability Help?","type":"talk"},{"authors":[],"categories":null,"content":"","date":1661868000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1661868000,"objectID":"0c77442923baa3a3103d37428adb2371","permalink":"http://weihan95.com/talk/dynamic-neural-networks/","publishdate":"2022-08-30T20:00:00Z","relpermalink":"/talk/dynamic-neural-networks/","section":"talk","summary":" ","tags":[],"title":"Dynamic Neural Networks","type":"talk"},{"authors":["Bernard M. Cobbinah","Christian Sorg","Qinli Yang","Arvid Ternblom","Changgang Zheng","Wei Han","Liwei Che","Junming Shao"],"categories":null,"content":"","date":1660521600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660521600,"objectID":"d683726bc4b8fa46bcec10661663d508","permalink":"http://weihan95.com/publication/medical_image_analysis2022/","publishdate":"2022-08-15T00:00:00Z","relpermalink":"/publication/medical_image_analysis2022/","section":"publication","summary":"Based on brain magnetic resonance imaging (MRI), multiple variations ranging from MRI scanners to centerspecific parameter settings, imaging protocols, and brain region-of-interest (ROI) definitions pose a big challenge for multi-center Alzheimer's disease characterization and classification. Existing approaches to reduce such variations require intricate multi-step, often manual preprocessing pipelines, including skull stripping, segmentation, registration, cortical reconstruction, and ROI outlining. Such procedures are time-consuming, and more importantly, tend to be user biased. Contrasting costly and biased preprocessing pipelines, the question arises whether we can design a deep learning model to automatically reduce these variations from multiple centers for Alzheimer's disease classification? In this study, we used T1 and T2-weighted structural MRI from Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset based on three groups with 375 subjects, respectively, patients with Alzheimer's disease (AD) dementia, with mild cognitive impairment (MCI), and healthy controls (HC); to test our approach, we defined AD classification as classifying an individual's structural image to one of the three group labels. We first introduced a convolutional adversarial autoencoder (CAAE) to reduce the variations existing in multi-center raw MRI scans by automatically registering them into a common aligned space. Afterward, a convolutional residual soft attention network (CRAT) was further proposed for AD classification. Canonical classification procedures demonstrated that our model achieved classification accuracies of 91.8%, 90.05%, and 88.10% for the 2-way classification tasks using the RAW aligned MRI scans, including AD vs. HC, AD vs. MCI, and MCI vs. HC, respectively. Thus, our automated approach achieves comparable or even better classification performance by comparing it with many baselines with dedicated conventional preprocessing pipelines. Furthermore, the uncovered brain hotpots, i.e., hippocampus, amygdala, and temporal pole, are consistent with previous studies.","tags":["Alzheimer's disease classification","Multi-center MRIs","Convolutional adversarial autoencoder","Convolutional attention network"],"title":"Reducing variations in multi-center Alzheimer’s disease classification with convolutional adversarial autoencoder","type":"publication"},{"authors":["Wei Han","Yangqiming Wang","Christian Boehm","Junming Shao"],"categories":null,"content":"","date":1660435200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1660435200,"objectID":"069a7bb0e41b999bc8570de8ddc4c94a","permalink":"http://weihan95.com/publication/vds_kdd2022/","publishdate":"2022-08-14T00:00:00Z","relpermalink":"/publication/vds_kdd2022/","section":"publication","summary":"Although deep neural networks have shown well-performance in various tasks, the poor interpretability of the models is always criticized. In the paper, we propose a new interpretable neural network method, by embedding neurons into the semantic space to extract their intrinsic global semantics. In contrast to previous methods that probe latent knowledge inside the model, the proposed semantic vector externalizes the latent knowledge to static knowledge, which is easy to exploit. Specifically, we assume that neurons with similar activation are of similar semantic information. Afterwards, semantic vectors are optimized by continuously aligning activation similarity and semantic vector similarity during the training of the neural network. The visualization of semantic vectors allows for a qualitative explanation of the neural network. Moreover, we assess the static knowledge quantitatively by knowledge distillation tasks. Empirical experiments of visualization show that semantic vectors describe neuron activation semantics well. Without the sample-by-sample guidance from the teacher model, static knowledge distillation exhibit comparable or even superior performance with existing relation-based knowledge distillation methods.","tags":["Neural network interpretability","semantic embedding","knowledge distillation"],"title":"An Interpretable Neuron Embedding for Static Knowledge Distillation","type":"publication"},{"authors":["Zhili Qin","Han Wang","Cobbinah Bernard Mawuli,","Wei Han","Rui Zhang,","Qinli Yang","Junming Shao"],"categories":null,"content":"","date":1656720000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1656720000,"objectID":"f6eba7864f7808b9c94e5e1d1ad9a44d","permalink":"http://weihan95.com/publication/information_science2022/","publishdate":"2022-07-02T00:00:00Z","relpermalink":"/publication/information_science2022/","section":"publication","summary":"The attention mechanism is usually equipped with a few-shot learning framework and plays a key role in extracting the semantic object(s). However, most attention networks in existing few-shot learning algorithms often work on the channel and/or pixel dimension, leading to the size of attention maps being large. Due to lack of training examples, these attention networks are prone to over-fitting, and may fail to find the semantic target(s). In this paper, we split the original image into patches, extending a new dimension in image data, namely, the patch dimension. On the one hand, the number of patch dimensions is usually much smaller than the traditional three dimensions, thus greatly reducing the number of attention module parameters. On the other hand, the patch dimensional attention mechanism can benefit from multi-instance learning and achieve a good compromise between global and local features. Four comparison experiments on four typical real-world data sets (miniImageNet, tieredImageNet, Fewshot-CIFAR100, Caltech-UCSD Birds-200– 2011) have demonstrated that our proposed algorithm achieves consistent improvement over 6 baseline models (Matching Networks, Relation Networks, Prototypical Networks, MAML, Baseline++, Meta Baseline) and 11 state-of-the-art models (DC, TapNet, SNAIL, TADAM, MetaOptNet, CAN, CTM, DCEM, AFHN, LEO, AWGIM). Our code is available at (https://github.com/rumorgin/MIAN).","tags":["Few-shot learning","Multi-instance learning","Self-attention network"],"title":"Multi-instance attention network for few-shot learning","type":"publication"},{"authors":[],"categories":null,"content":"","date":1632837600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632837600,"objectID":"a1af05aba32a69f21d77a9e3ec37779d","permalink":"http://weihan95.com/talk/recent-advances-of-continual-learning/","publishdate":"2021-09-28T20:00:00Z","relpermalink":"/talk/recent-advances-of-continual-learning/","section":"talk","summary":" ","tags":[],"title":"Recent Advances of Continual Learning","type":"talk"},{"authors":["Wei Han","Changgang Zheng","Rui Zhang","Jinxia Guo","Qinli Yang","Junming Shao"],"categories":null,"content":"","date":1620691200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1620691200,"objectID":"e8722f6ee66af73dc7ec3178f47bb0a4","permalink":"http://weihan95.com/publication/information_science2021/","publishdate":"2021-05-11T00:00:00Z","relpermalink":"/publication/information_science2021/","section":"publication","summary":"Modular is a powerful and inherently hierarchical concept in the human brain to process a large variety of complex tasks. Converging evidence has shown several advantages to hierarchically modular network organizations in the human brain such as interpretability and evolvability of network function. Inspired by previous neuroscience studies, we propose MNN-CH, a novel modular neural network that is constructed with explored category hierarchy. The basic idea is learning to learn an optimized category hierarchy to decompose complex patterns. And specific patterns are imposed into corresponding modules to realize a transparent design of the neural network. Specifically, for a given classification task, each class or superclass is first represented as a prototype. Afterward, the category hierarchy is initially determined by investigating class similarity and gather similar ones to train each branch neural network (i.e., modular) separately. Finally, an error-driven prototype learning is introduced to refine the category hierarchy by updating the class-superclass affiliation. Experiment results on several image classification datasets show that our model has a good performance, especially in complex tasks. Beyond, we conduct an analysis to illustrate the tree-manner interpretability of the modular neural network.","tags":["Modular neural network","Interpretable machine learning","Image classification","Category hierarchy","Learning to learn"],"title":"Modular neural network via exploring category hierarchy","type":"publication"},{"authors":[],"categories":null,"content":"","date":1619618400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619618400,"objectID":"deea2b3ec3e6d6d4f1af15933865f0ab","permalink":"http://weihan95.com/talk/net2vec-towards-knowledge-embedding/","publishdate":"2021-04-28T20:00:00Z","relpermalink":"/talk/net2vec-towards-knowledge-embedding/","section":"talk","summary":" ","tags":[],"title":"Net2Vec towards Knowledge Embedding","type":"talk"},{"authors":[],"categories":null,"content":"","date":1606831200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606831200,"objectID":"929964e0a725e5ee94776d35c222da87","permalink":"http://weihan95.com/talk/informtion-theory-in-deep-neural-networks/","publishdate":"2020-12-01T20:00:00Z","relpermalink":"/talk/informtion-theory-in-deep-neural-networks/","section":"talk","summary":" ","tags":[],"title":"informtion theory in deep neural networks","type":"talk"},{"authors":[],"categories":null,"content":"","date":1595340000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595340000,"objectID":"638e261350be01d02e1796219d3b72af","permalink":"http://weihan95.com/talk/an-efficient-network-architecture-before-and-after-training/","publishdate":"2020-07-21T20:00:00Z","relpermalink":"/talk/an-efficient-network-architecture-before-and-after-training/","section":"talk","summary":" ","tags":[],"title":"An Efficient Network Architecture Before and After Training","type":"talk"},{"authors":[],"categories":null,"content":"","date":1569333600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569333600,"objectID":"7ca7d7c88ecb7c8cd055aecc7accb626","permalink":"http://weihan95.com/talk/some-advances-of-neural-network-architecture-in-image-classification/","publishdate":"2019-09-24T20:00:00Z","relpermalink":"/talk/some-advances-of-neural-network-architecture-in-image-classification/","section":"talk","summary":" ","tags":[],"title":"Some Advances of Neural Network Architecture in Image Classification","type":"talk"},{"authors":[],"categories":null,"content":"","date":1560261600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560261600,"objectID":"4e48f8d2b42a62d27377afde3fda7439","permalink":"http://weihan95.com/talk/modular-neural-network/","publishdate":"2019-06-11T20:00:00Z","relpermalink":"/talk/modular-neural-network/","section":"talk","summary":" ","tags":[],"title":"Modular Neural Network","type":"talk"},{"authors":["Wei Han","Christian Sorg","Changgang Zheng","Qinli Yang","Xiaosong Zhang","Arvid Ternblom","Cobbinah Bernard Mawuli","Lianli Gao","Cheng Luo","Dezhong Yao","Tao Li","Sugai Liang","Junming Shao"],"categories":null,"content":"","date":1550793600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561626340,"objectID":"cc6dedbb33d947edbee81a71aa8bbb6e","permalink":"http://weihan95.com/publication/neuroimage2019/","publishdate":"2019-02-22T00:00:00Z","relpermalink":"/publication/neuroimage2019/","section":"publication","summary":"Brain imaging studies have revealed that functional and structural brain connectivity in the so-called triple network (i.e., default mode network (DMN), salience network (SN) and central executive network (CEN)) are consistently altered in schizophrenia. However, similar changes have also been found in patients with major depressive disorder, prompting the question of specific triple network signatures for the two disorders. In this study, we proposed Supervised Convex Nonnegative Matrix Factorization (SCNMF) to extract distributed multimodal brain patterns. These patterns distinguish schizophrenia and major depressive disorder in a latent lowdimensional space of the triple brain network. Specifically, 21 patients of schizophrenia and 25 patients of major depressive disorder were assessed by T1-weighted, diffusion-weighted, and resting-state functional MRIs. Individual structural and functional connectivity networks, based on pre-defined regions of the triple network were constructed, respectively. Afterwards, SCNMF was employed to extract the discriminative patterns. Experiments indicate that SCNMF allows extracting the low-rank discriminative patterns between the two disorders, achieving a classification accuracy of 82.6% based on the extracted functional and structural abnormalities with support vector machine. Experimental results show the specific brain patterns for schizophrenia and major depressive disorder that are multi-modal, complex, and distributed in the triple network. Parts of the prefrontal cortex including superior frontal gyri showed variation between patients with schizophrenia and major depression due to structural properties. In terms of functional properties, the middle cingulate cortex, inferior parietal lobule, and cingulate cortex were the most discriminative regions.","tags":["Nonnegative Matrix Factorization","Neuroimaging"],"title":"Low-rank Network Signatures in the Triple Network Separate Schizophrenia and Major Depressive Disorder","type":"publication"},{"authors":[],"categories":null,"content":"","date":1544259600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561550268,"objectID":"701d4cb2566d268db35077778edb090a","permalink":"http://weihan95.com/talk/capsule-neural-network-and-discussion-on-synchronization-neural-network/","publishdate":"2018-12-08T20:00:00Z","relpermalink":"/talk/capsule-neural-network-and-discussion-on-synchronization-neural-network/","section":"talk","summary":" ","tags":["Interpretable Machine Learning","Representation Learning","Deep Neural Network"],"title":"Capsule Neural Network and Discussion on Synchronization Neural Network","type":"talk"},{"authors":[],"categories":null,"content":"","date":1533027600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561621736,"objectID":"7fee6c478189df822d1ef10f27838aeb","permalink":"http://weihan95.com/talk/tutorial-on-tensorflow-usage/","publishdate":"2018-07-31T20:00:00Z","relpermalink":"/talk/tutorial-on-tensorflow-usage/","section":"talk","summary":" ","tags":["Python","Tensorflow","Deep Neural Network"],"title":"Tutorial on tensorflow usage","type":"talk"},{"authors":["Junming Shao","Zhongjing Yu","Peiyan Li","Wei Han","Christian Sorg","Qinli Yang"],"categories":null,"content":"","date":1502956704,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561550268,"objectID":"6847b4ab4f6a43abd0fbe6ff44f1b82b","permalink":"http://weihan95.com/publication/icdm2017/","publishdate":"2017-08-17T15:58:24+08:00","relpermalink":"/publication/icdm2017/","section":"publication","summary":"In this paper, we introduce a novel method to discover common and distinct structural connectivity patterns between SZP and MDD via a Cluster-Driven Nonnegative Matrix Factorization (called CD-NMF). Specifically, CD-NMF is applied to decompose the joint structural connectivity map into common and distinct parts, and each part is further factorized into two sub-matrices (i.e. common/distinct basis matrix and common/distinct encoding matrix) correspondingly. By imposing the clustering constraints on common and distinct encoding matrices, the discriminative patterns as well as the common patterns between the two disorders are extracted simultaneously. Experimental results demonstrate that CDNMF allows finding the common and distinct structural patterns effectively. More importantly, the derived distinct patterns, show powerful ability to discriminate the patients of schizophrenia and major depressive disorder.","tags":["Nonnegative Matrix Factorization","Neuroimaging"],"title":"Exploring Common and Distinct Structural Connectivity Patterns Between Schizophrenia and Major Depression via Cluster-Driven Nonnegative Matrix Factorization","type":"publication"},{"authors":[],"categories":null,"content":"","date":1501059600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561550268,"objectID":"8967fe1479e86d9fdff65f5dc55ec22f","permalink":"http://weihan95.com/talk/representation-based-transfer-learning-and-some-advances/","publishdate":"2017-07-26T20:00:00Z","relpermalink":"/talk/representation-based-transfer-learning-and-some-advances/","section":"talk","summary":" ","tags":["Transfer Learning","Adversarial Learning"],"title":"Representation-based Transfer Learning and Some Advances","type":"talk"},{"authors":[],"categories":null,"content":"","date":1493802000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561550268,"objectID":"4516dde8eda16063ae686ad1f2a4d17e","permalink":"http://weihan95.com/talk/label-distribution-learning/","publishdate":"2017-05-03T20:00:00Z","relpermalink":"/talk/label-distribution-learning/","section":"talk","summary":" ","tags":["Classification"],"title":"Label Distribution Learning","type":"talk"},{"authors":[],"categories":null,"content":"","date":1479286800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561550268,"objectID":"45dde897d2784ca4dabd93b75ca279cb","permalink":"http://weihan95.com/talk/preliminary-study-of-deep-learning/","publishdate":"2016-11-16T20:00:00Z","relpermalink":"/talk/preliminary-study-of-deep-learning/","section":"talk","summary":" ","tags":[],"title":"Preliminary Study of Deep Learning","type":"talk"},{"authors":["Jiaming Liu,","Jun Tian,","Wei Han","Zhili Qin,","Yulu Fan,","Junming Shao"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"3d839fe60b9be7b3d9e546eb76c0a3de","permalink":"http://weihan95.com/publication/information_science2023/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/publication/information_science2023/","section":"publication","summary":"Open-set recognition aims to deal with unknown classes that do not exist in the training phase. The key is to learn effective latent feature representations for classifying the already known classes as well as detecting new emerging ones. In this paper, we learn multiple Gaussian prototypes to better represent the complex classes distribution in both generative and discriminative ways. With the generative constraint, the latent variables of the same class clusters compactly around the corresponding Gaussian prototypes, preserving extra space for the samples of unknown classes. The discriminative constraint separates the Gaussian prototypes of different classes, which further improves the discrimination capability for the known classes. Importantly, the entire framework can be directly derived from the Bayesian inference, thus providing theoretical support for open-set recognition. Experimental results of different datasets verify the reliability and effectiveness of the proposed method. Our code is available at https://github. com/LiuJMzzZ/MGPL.","tags":["Open-set recognition","Novelty detection","Gaussian prototype","Variational auto-encoder"],"title":"Learning multiple gaussian prototypes for open-set recognition","type":"publication"}]